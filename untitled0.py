# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uFOT5h4f59bKAAsV7UEpUmZ_XK53U5g_
"""

import torch
print("GPU available:", torch.cuda.is_available())
print("Device:", torch.device("cuda" if torch.cuda.is_available() else "cpu"))

!pip -q install kagglehub
!pip -q install scikit-learn

import kagglehub

path = kagglehub.dataset_download("abdallahalidev/plantvillage-dataset")
print("Path to dataset files:", path)

from pathlib import Path
import os

dataset_path = Path(path)

def find_class_root(base: Path):
    # find a folder that contains many class folders
    candidates = []
    for p in base.rglob("*"):
        if p.is_dir():
            subdirs = [x for x in p.iterdir() if x.is_dir()]
            if len(subdirs) > 10:  # PlantVillage usually has many classes
                # check if those subdirs contain images
                img_count = sum(len(list(sd.glob("*.jpg"))) + len(list(sd.glob("*.png"))) for sd in subdirs[:5])
                if img_count > 0:
                    candidates.append((p, len(subdirs), img_count))
    candidates.sort(key=lambda x: (x[1], x[2]), reverse=True)
    return candidates[0][0] if candidates else None

root = find_class_root(dataset_path)
print("Detected root:", root)

# show a few class folders
print("Sample class folders:", [p.name for p in list(root.iterdir())[:10]])

tomato_classes = sorted([p for p in root.iterdir() if p.is_dir() and p.name.lower().startswith("tomato")])
print("Tomato classes found:", len(tomato_classes))
print([p.name for p in tomato_classes])

import pandas as pd

rows = []
for class_dir in tomato_classes:
    for ext in ("*.jpg", "*.jpeg", "*.png"):
        for img_path in class_dir.glob(ext):
            rows.append((str(img_path), class_dir.name))

df = pd.DataFrame(rows, columns=["filepath", "label"])
print("Total tomato images:", len(df))
df["label"].value_counts()

from sklearn.model_selection import train_test_split

train_df, val_df = train_test_split(
    df,
    test_size=0.2,
    random_state=42,
    stratify=df["label"]
)

print("Train:", len(train_df), "Val:", len(val_df))

from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# Label encoding
classes = sorted(df["label"].unique())
class_to_idx = {c:i for i,c in enumerate(classes)}
idx_to_class = {i:c for c,i in class_to_idx.items()}

print("Num classes:", len(classes))
print(classes)

train_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

val_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

class TomatoDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.df = dataframe.reset_index(drop=True)
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        fp = self.df.loc[idx, "filepath"]
        label = self.df.loc[idx, "label"]
        y = class_to_idx[label]

        img = Image.open(fp).convert("RGB")
        if self.transform:
            img = self.transform(img)
        return img, y

train_ds = TomatoDataset(train_df, transform=train_tfms)
val_ds   = TomatoDataset(val_df, transform=val_tfms)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)

len(train_loader), len(val_loader)

import torch
import torch.nn as nn
from torchvision import models

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)

# Freeze backbone initially
for p in model.parameters():
    p.requires_grad = False

# Replace classifier head
in_features = model.classifier[3].in_features
model.classifier[3] = nn.Linear(in_features, len(classes))

model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3)

print(model.__class__.__name__)

from tqdm import tqdm
import numpy as np

def accuracy_from_logits(logits, y):
    preds = torch.argmax(logits, dim=1)
    return (preds == y).float().mean().item()

epochs = 8

for epoch in range(1, epochs + 1):
    model.train()
    train_loss = 0.0
    train_acc = 0.0

    for x, y in tqdm(train_loader, desc=f"Epoch {epoch}/{epochs} [train]"):
        x, y = x.to(device), y.to(device)

        optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits, y)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_acc += accuracy_from_logits(logits, y)

    train_loss /= len(train_loader)
    train_acc /= len(train_loader)

    model.eval()
    val_loss = 0.0
    val_acc = 0.0

    with torch.no_grad():
        for x, y in tqdm(val_loader, desc=f"Epoch {epoch}/{epochs} [val]"):
            x, y = x.to(device), y.to(device)
            logits = model(x)
            loss = criterion(logits, y)

            val_loss += loss.item()
            val_acc += accuracy_from_logits(logits, y)

    val_loss /= len(val_loader)
    val_acc /= len(val_loader)

    print(f"Epoch {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}")

# Unfreeze last ~20% of parameters (simple approach: unfreeze the whole backbone with a low LR)
for p in model.parameters():
    p.requires_grad = True

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

fine_tune_epochs = 3

for epoch in range(1, fine_tune_epochs + 1):
    model.train()
    train_loss = 0.0
    train_acc = 0.0

    for x, y in tqdm(train_loader, desc=f"FineTune {epoch}/{fine_tune_epochs} [train]"):
        x, y = x.to(device), y.to(device)

        optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits, y)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_acc += accuracy_from_logits(logits, y)

    train_loss /= len(train_loader)
    train_acc /= len(train_loader)

    model.eval()
    val_loss = 0.0
    val_acc = 0.0

    with torch.no_grad():
        for x, y in tqdm(val_loader, desc=f"FineTune {epoch}/{fine_tune_epochs} [val]"):
            x, y = x.to(device), y.to(device)
            logits = model(x)
            loss = criterion(logits, y)
            val_loss += loss.item()
            val_acc += accuracy_from_logits(logits, y)

    val_loss /= len(val_loader)
    val_acc /= len(val_loader)

    print(f"FineTune {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}")

from sklearn.metrics import classification_report, confusion_matrix

model.eval()
all_true = []
all_pred = []

with torch.no_grad():
    for x, y in val_loader:
        x = x.to(device)
        logits = model(x)
        preds = torch.argmax(logits, dim=1).cpu().numpy()

        all_pred.extend(list(preds))
        all_true.extend(list(y.numpy()))

print(classification_report(all_true, all_pred, target_names=classes))

import torch

save_path = "tomato_leaf_disease_mobilenetv3.pth"
torch.save({
    "model_state": model.state_dict(),
    "classes": classes
}, save_path)

print("Saved to:", save_path)

from google.colab import files
uploaded = files.upload()
list(uploaded.keys())

import torch
from PIL import Image
import matplotlib.pyplot as plt

def predict_image(image_path):
    model.eval()
    img = Image.open(image_path).convert("RGB")

    x = val_tfms(img).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model(x)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

    top_idx = int(probs.argmax())
    pred_label = classes[top_idx]
    confidence = float(probs[top_idx])

    plt.figure()
    plt.imshow(img)
    plt.axis("off")
    plt.title(f"Prediction: {pred_label}\nConfidence: {confidence:.3f}")
    plt.show()

    # show top 5
    top5 = probs.argsort()[-5:][::-1]
    print("Top-5 predictions:")
    for i in top5:
        print(f"{classes[i]:45s}  {probs[i]:.4f}")

# pick the first uploaded file
img_name = list(uploaded.keys())[0]
predict_image(img_name)